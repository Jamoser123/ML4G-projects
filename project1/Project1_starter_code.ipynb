{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries that are required to run your project\n",
    "# You are allowed to add more libraries as you need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful to initiate new conda environment given the yml file (Note I adjusted it to work for windows)\n",
    "```bash\n",
    "conda env create -f project1_base.yml -n ml4g_project1\n",
    "```\n",
    "\n",
    "Note: Maybe we rather make a new one, since it hasn't been updated for 4 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CAGE-train.zip...\n",
      "  Copied X1_train_info.tsv to CAGE-train/\n",
      "  Copied X1_train_y.tsv to CAGE-train/\n",
      "  Copied X1_val_info.tsv to CAGE-train/\n",
      "  Copied X1_val_y.tsv to CAGE-train/\n",
      "  Copied X2_train_info.tsv to CAGE-train/\n",
      "  Copied X2_train_y.tsv to CAGE-train/\n",
      "  Copied X2_val_info.tsv to CAGE-train/\n",
      "  Copied X1_train_y.tsv to CAGE-train/\n",
      "  Copied X1_val_info.tsv to CAGE-train/\n",
      "  Copied X1_val_y.tsv to CAGE-train/\n",
      "  Copied X2_train_info.tsv to CAGE-train/\n",
      "  Copied X2_train_y.tsv to CAGE-train/\n",
      "  Copied X2_val_info.tsv to CAGE-train/\n",
      "  Copied X2_val_y.tsv to CAGE-train/\n",
      "  Copied X3_test_info.tsv to CAGE-train/\n",
      "  Copied ._X1_train_info.tsv to CAGE-train/\n",
      "  Copied ._X1_train_y.tsv to CAGE-train/\n",
      "  Copied ._X3_test_info.tsv to CAGE-train/\n",
      "  Cleaned up temp_CAGE-train\n",
      "Processing DNase-bed.zip...\n",
      "  Copied X2_val_y.tsv to CAGE-train/\n",
      "  Copied X3_test_info.tsv to CAGE-train/\n",
      "  Copied ._X1_train_info.tsv to CAGE-train/\n",
      "  Copied ._X1_train_y.tsv to CAGE-train/\n",
      "  Copied ._X3_test_info.tsv to CAGE-train/\n",
      "  Cleaned up temp_CAGE-train\n",
      "Processing DNase-bed.zip...\n",
      "  Copied X1.bed -> X1/DNase_X1.bed\n",
      "  Copied X2.bed -> X2/DNase_X2.bed\n",
      "  Copied X3.bed -> X3/DNase_X3.bed\n",
      "  Cleaned up temp_DNase-bed\n",
      "Processing DNase-bigwig.zip...\n",
      "  Copied X1.bed -> X1/DNase_X1.bed\n",
      "  Copied X2.bed -> X2/DNase_X2.bed\n",
      "  Copied X3.bed -> X3/DNase_X3.bed\n",
      "  Cleaned up temp_DNase-bed\n",
      "Processing DNase-bigwig.zip...\n",
      "  Copied X1.bw -> X1/DNase_X1.bw\n",
      "  Copied X1.bw -> X1/DNase_X1.bw\n",
      "  Copied X2.bw -> X2/DNase_X2.bw\n",
      "  Copied X2.bw -> X2/DNase_X2.bw\n",
      "  Copied X3.bigwig -> X3/DNase_X3.bw\n",
      "  Cleaned up temp_DNase-bigwig\n",
      "Processing H3K27ac-bed.zip...\n",
      "  Copied X3.bigwig -> X3/DNase_X3.bw\n",
      "  Cleaned up temp_DNase-bigwig\n",
      "Processing H3K27ac-bed.zip...\n",
      "  Copied X1.bed -> X1/H3K27ac_X1.bed\n",
      "  Copied X2.bed -> X2/H3K27ac_X2.bed\n",
      "  Copied X3.bed -> X3/H3K27ac_X3.bed\n",
      "  Cleaned up temp_H3K27ac-bed\n",
      "Processing H3K27ac-bigwig.zip...\n",
      "  Copied X1.bed -> X1/H3K27ac_X1.bed\n",
      "  Copied X2.bed -> X2/H3K27ac_X2.bed\n",
      "  Copied X3.bed -> X3/H3K27ac_X3.bed\n",
      "  Cleaned up temp_H3K27ac-bed\n",
      "Processing H3K27ac-bigwig.zip...\n",
      "  Copied X1.bigwig -> X1/H3K27ac_X1.bw\n",
      "  Copied X1.bigwig -> X1/H3K27ac_X1.bw\n",
      "  Copied X2.bw -> X2/H3K27ac_X2.bw\n",
      "  Copied X2.bw -> X2/H3K27ac_X2.bw\n",
      "  Copied X3.bw -> X3/H3K27ac_X3.bw\n",
      "  Copied X3.bw -> X3/H3K27ac_X3.bw\n",
      "  Cleaned up temp_H3K27ac-bigwig\n",
      "Processing H3K27me3-bed.zip...\n",
      "  Copied X1.bed -> X1/H3K27me3_X1.bed\n",
      "  Copied X2.bed -> X2/H3K27me3_X2.bed\n",
      "  Cleaned up temp_H3K27ac-bigwig\n",
      "Processing H3K27me3-bed.zip...\n",
      "  Copied X1.bed -> X1/H3K27me3_X1.bed\n",
      "  Copied X2.bed -> X2/H3K27me3_X2.bed\n",
      "  Copied X3.bed -> X3/H3K27me3_X3.bed\n",
      "  Cleaned up temp_H3K27me3-bed\n",
      "Processing H3K27me3-bigwig.zip...\n",
      "  Copied X3.bed -> X3/H3K27me3_X3.bed\n",
      "  Cleaned up temp_H3K27me3-bed\n",
      "Processing H3K27me3-bigwig.zip...\n",
      "  Copied X1.bw -> X1/H3K27me3_X1.bw\n",
      "  Copied X1.bw -> X1/H3K27me3_X1.bw\n",
      "  Copied X2.bw -> X2/H3K27me3_X2.bw\n",
      "  Copied X2.bw -> X2/H3K27me3_X2.bw\n",
      "  Copied X3.bigwig -> X3/H3K27me3_X3.bw\n",
      "  Copied X3.bigwig -> X3/H3K27me3_X3.bw\n",
      "  Cleaned up temp_H3K27me3-bigwig\n",
      "Processing H3K36me3-bed.zip...\n",
      "  Cleaned up temp_H3K27me3-bigwig\n",
      "Processing H3K36me3-bed.zip...\n",
      "  Copied X1.bed -> X1/H3K36me3_X1.bed\n",
      "  Copied X2.bed -> X2/H3K36me3_X2.bed\n",
      "  Copied X3.bed -> X3/H3K36me3_X3.bed\n",
      "  Cleaned up temp_H3K36me3-bed\n",
      "Processing H3K36me3-bigwig.zip...\n",
      "  Copied X1.bed -> X1/H3K36me3_X1.bed\n",
      "  Copied X2.bed -> X2/H3K36me3_X2.bed\n",
      "  Copied X3.bed -> X3/H3K36me3_X3.bed\n",
      "  Cleaned up temp_H3K36me3-bed\n",
      "Processing H3K36me3-bigwig.zip...\n",
      "  Copied X1.bw -> X1/H3K36me3_X1.bw\n",
      "  Copied X1.bw -> X1/H3K36me3_X1.bw\n",
      "  Copied X2.bw -> X2/H3K36me3_X2.bw\n",
      "  Copied X2.bw -> X2/H3K36me3_X2.bw\n",
      "  Copied X3.bigwig -> X3/H3K36me3_X3.bw\n",
      "  Copied X3.bigwig -> X3/H3K36me3_X3.bw\n",
      "  Cleaned up temp_H3K36me3-bigwig\n",
      "Processing H3K4me1-bed.zip...\n",
      "  Cleaned up temp_H3K36me3-bigwig\n",
      "Processing H3K4me1-bed.zip...\n",
      "  Copied X1.bed -> X1/H3K4me1_X1.bed\n",
      "  Copied X2.bed -> X2/H3K4me1_X2.bed\n",
      "  Copied X3.bed -> X3/H3K4me1_X3.bed\n",
      "  Cleaned up temp_H3K4me1-bed\n",
      "Processing H3K4me1-bigwig.zip...\n",
      "  Copied X1.bed -> X1/H3K4me1_X1.bed\n",
      "  Copied X2.bed -> X2/H3K4me1_X2.bed\n",
      "  Copied X3.bed -> X3/H3K4me1_X3.bed\n",
      "  Cleaned up temp_H3K4me1-bed\n",
      "Processing H3K4me1-bigwig.zip...\n",
      "  Copied X1.bigwig -> X1/H3K4me1_X1.bw\n",
      "  Copied X1.bigwig -> X1/H3K4me1_X1.bw\n",
      "  Copied X2.bw -> X2/H3K4me1_X2.bw\n",
      "  Copied X2.bw -> X2/H3K4me1_X2.bw\n",
      "  Copied X3.bw -> X3/H3K4me1_X3.bw\n",
      "  Copied X3.bw -> X3/H3K4me1_X3.bw\n",
      "  Cleaned up temp_H3K4me1-bigwig\n",
      "Processing H3K4me3-bed.zip...\n",
      "  Cleaned up temp_H3K4me1-bigwig\n",
      "Processing H3K4me3-bed.zip...\n",
      "  Copied X1.bed -> X1/H3K4me3_X1.bed\n",
      "  Copied X2.bed -> X2/H3K4me3_X2.bed\n",
      "  Copied X3.bed -> X3/H3K4me3_X3.bed\n",
      "  Cleaned up temp_H3K4me3-bed\n",
      "Processing H3K4me3-bigwig.zip...\n",
      "  Copied X1.bed -> X1/H3K4me3_X1.bed\n",
      "  Copied X2.bed -> X2/H3K4me3_X2.bed\n",
      "  Copied X3.bed -> X3/H3K4me3_X3.bed\n",
      "  Cleaned up temp_H3K4me3-bed\n",
      "Processing H3K4me3-bigwig.zip...\n",
      "  Copied X1.bw -> X1/H3K4me3_X1.bw\n",
      "  Copied X1.bw -> X1/H3K4me3_X1.bw\n",
      "  Copied X2.bw -> X2/H3K4me3_X2.bw\n",
      "  Copied X2.bw -> X2/H3K4me3_X2.bw\n",
      "  Copied X3.bigwig -> X3/H3K4me3_X3.bw\n",
      "  Copied X3.bigwig -> X3/H3K4me3_X3.bw\n",
      "  Cleaned up temp_H3K4me3-bigwig\n",
      "Processing H3K9me3-bed.zip...\n",
      "  Cleaned up temp_H3K4me3-bigwig\n",
      "Processing H3K9me3-bed.zip...\n",
      "  Copied X1.bed -> X1/H3K9me3_X1.bed\n",
      "  Copied X2.bed -> X2/H3K9me3_X2.bed\n",
      "  Copied X3.bed -> X3/H3K9me3_X3.bed\n",
      "  Cleaned up temp_H3K9me3-bed\n",
      "Processing H3K9me3-bigwig.zip...\n",
      "  Copied X1.bed -> X1/H3K9me3_X1.bed\n",
      "  Copied X2.bed -> X2/H3K9me3_X2.bed\n",
      "  Copied X3.bed -> X3/H3K9me3_X3.bed\n",
      "  Cleaned up temp_H3K9me3-bed\n",
      "Processing H3K9me3-bigwig.zip...\n",
      "  Copied X1.bw -> X1/H3K9me3_X1.bw\n",
      "  Copied X1.bw -> X1/H3K9me3_X1.bw\n",
      "  Copied X2.bw -> X2/H3K9me3_X2.bw\n",
      "  Copied X2.bw -> X2/H3K9me3_X2.bw\n",
      "  Copied X3.bigwig -> X3/H3K9me3_X3.bw\n",
      "  Copied ._X1.bw -> X1/H3K9me3_X1.bw\n",
      "  Copied X3.bigwig -> X3/H3K9me3_X3.bw\n",
      "  Copied ._X1.bw -> X1/H3K9me3_X1.bw\n",
      "  Copied ._X2.bw -> X2/H3K9me3_X2.bw\n",
      "  Copied ._X2.bw -> X2/H3K9me3_X2.bw\n",
      "  Cleaned up temp_H3K9me3-bigwig\n",
      "\n",
      "All 15 zip files have been extracted and organized in data\n",
      "Structure: data/{X1,X2,X3}/{DataType}_{CellLine}.{bw,bed}\n",
      "  Cleaned up temp_H3K9me3-bigwig\n",
      "\n",
      "All 15 zip files have been extracted and organized in data\n",
      "Structure: data/{X1,X2,X3}/{DataType}_{CellLine}.{bw,bed}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "source_dir = 'ML4G_Project_1_Data'  # Path to directory with zip files\n",
    "target_dir = 'data'  # Target directory for extracted files\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Create folders for each cell line\n",
    "cell_lines = ['X1', 'X2', 'X3']\n",
    "for cell_line in cell_lines:\n",
    "    cell_line_dir = os.path.join(target_dir, cell_line)\n",
    "    os.makedirs(cell_line_dir, exist_ok=True)\n",
    "\n",
    "# Get all zip files in the source directory (excluding sample.zip)\n",
    "zip_files = [f for f in os.listdir(source_dir) if f.endswith('.zip') and f != 'sample.zip']\n",
    "\n",
    "# Process each zip file separately\n",
    "for zip_file in zip_files:\n",
    "    zip_path = os.path.join(source_dir, zip_file)\n",
    "    zip_name = os.path.splitext(zip_file)[0]\n",
    "    print(f\"Processing {zip_file}...\")\n",
    "    \n",
    "    # Extract to a unique temporary directory for this zip file\n",
    "    temp_extract_dir = os.path.join(target_dir, f'temp_{zip_name}')\n",
    "    os.makedirs(temp_extract_dir, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_extract_dir)\n",
    "    \n",
    "    # Walk through all extracted files from this zip and organize them\n",
    "    for root, dirs, files in os.walk(temp_extract_dir):\n",
    "        for file in files:\n",
    "            source_file = os.path.join(root, file)\n",
    "            \n",
    "            # Handle CAGE-train files separately\n",
    "            if 'CAGE-train' in root or file.endswith('.tsv'):\n",
    "                # Keep CAGE-train files in their own folder\n",
    "                cage_train_target = os.path.join(target_dir, 'CAGE-train')\n",
    "                os.makedirs(cage_train_target, exist_ok=True)\n",
    "                \n",
    "                # Preserve the relative path structure for CAGE files\n",
    "                rel_path = os.path.relpath(source_file, temp_extract_dir)\n",
    "                target_file = os.path.join(cage_train_target, rel_path)\n",
    "                os.makedirs(os.path.dirname(target_file), exist_ok=True)\n",
    "                shutil.copy2(source_file, target_file)\n",
    "                print(f\"  Copied {file} to CAGE-train/\")\n",
    "                continue\n",
    "            \n",
    "            # Determine which cell line this file belongs to\n",
    "            cell_line_found = False\n",
    "            for cell_line in cell_lines:\n",
    "                if cell_line in file:\n",
    "                    file_lower = file.lower()\n",
    "                    \n",
    "                    # Get file extension (handle both .bw and .bigwig)\n",
    "                    if file.endswith('.bw') or file.endswith('.bigwig'):\n",
    "                        ext = '.bw'\n",
    "                    elif file.endswith('.bed'):\n",
    "                        ext = '.bed'\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # Determine the mark/assay type from the zip file name\n",
    "                    zip_lower = zip_name.lower()\n",
    "                    if 'dnase' in zip_lower:\n",
    "                        data_type = 'DNase'\n",
    "                    elif 'h3k27ac' in zip_lower:\n",
    "                        data_type = 'H3K27ac'\n",
    "                    elif 'h3k27me3' in zip_lower:\n",
    "                        data_type = 'H3K27me3'\n",
    "                    elif 'h3k36me3' in zip_lower:\n",
    "                        data_type = 'H3K36me3'\n",
    "                    elif 'h3k4me1' in zip_lower:\n",
    "                        data_type = 'H3K4me1'\n",
    "                    elif 'h3k4me3' in zip_lower:\n",
    "                        data_type = 'H3K4me3'\n",
    "                    elif 'h3k9me3' in zip_lower:\n",
    "                        data_type = 'H3K9me3'\n",
    "                    else:\n",
    "                        # Skip if we can't identify the data type\n",
    "                        continue\n",
    "                    \n",
    "                    # Create new filename: {data_type}_{cell_line}{ext}\n",
    "                    new_filename = f\"{data_type}_{cell_line}{ext}\"\n",
    "                    target_file = os.path.join(target_dir, cell_line, new_filename)\n",
    "                    \n",
    "                    # Copy the file to the new location\n",
    "                    shutil.copy2(source_file, target_file)\n",
    "                    print(f\"  Copied {file} -> {cell_line}/{new_filename}\")\n",
    "                    cell_line_found = True\n",
    "                    break\n",
    "    \n",
    "    # Clean up this zip's temporary directory\n",
    "    shutil.rmtree(temp_extract_dir)\n",
    "    print(f\"  Cleaned up temp_{zip_name}\")\n",
    "\n",
    "print(f\"\\nAll {len(zip_files)} zip files have been extracted and organized in {target_dir}\")\n",
    "print(f\"Structure: data/{'{X1,X2,X3}'}/{'{DataType}_{CellLine}.{bw,bed}'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.1 - Modeling Choices & Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Load your feature (bed and/or bigwig and/or fasta) and target files (tsv) here.\n",
    "# Decide which features to use for training. Feel free to process them however you need.\n",
    "\n",
    "# NOTE: \n",
    "# bed and bigwig files contain signals of all chromosomes (including sex chromosomes).\n",
    "# Training and validation split based on chromosomes has been done for you. \n",
    "# However, you can resplit the data in any way you want.\n",
    "\n",
    "path_data = \"data\\\\CAGE-train\\\\CAGE-train\" \n",
    "path_test = \"data\\\\CAGE-train\\\\CAGE-train\\\\X3_test_info.tsv\"\n",
    "test_genes = pd.read_csv(path_test, sep='\\t')\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.2 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Select the best model to predict gene expression from the obtained features in WP 1.1.\n",
    "\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.3 - Prediction on Test Data (Evaluation Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Using the model trained in WP 1.2, make predictions on the test data (chr 1 of cell line X3).\n",
    "# Store predictions in a variable called \"pred\" which is a numpy array.\n",
    "pred: np.ndarray\n",
    "pred = np.array([])  # TODO\n",
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Check if \"pred\" meets the specified constrains\n",
    "assert isinstance(pred, np.ndarray), 'Prediction array must be a numpy array'\n",
    "assert np.issubdtype(pred.dtype, np.number), 'Prediction array must be numeric'\n",
    "assert pred.shape[0] == len(test_genes), 'Each gene should have a unique predicted expression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Predictions in the Required Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in a ZIP. \n",
    "# Upload this zip on the project website under \"Your submission\".\n",
    "# Zip this notebook along with the conda environment (and README, optional) and upload this under \"Your code\".\n",
    "\n",
    "save_dir = 'path/to/save/output/file'  # TODO\n",
    "file_name = 'gex_predicted.csv'         # PLEASE DO NOT CHANGE THIS\n",
    "zip_name = \"LastName_FirstName_Project1.zip\" # TODO\n",
    "save_path = f'{save_dir}/{zip_name}'\n",
    "compression_options = dict(method=\"zip\", archive_name=file_name)\n",
    "\n",
    "test_genes['gex_predicted'] = pred.tolist()\n",
    "test_genes[['gene_name', 'gex_predicted']].to_csv(save_path, compression=compression_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
